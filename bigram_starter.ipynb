{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPftyaWH0owHdXg9XOPKJT2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ezq0A9uNCVd","executionInfo":{"status":"ok","timestamp":1759858645669,"user_tz":240,"elapsed":221,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"3d815afd-e06b-4271-9571-7b940e8d1bb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-10-07 17:37:25--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘input.txt.1’\n","\n","\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n","\n","2025-10-07 17:37:25 (22.8 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n","\n"]}],"source":["# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n","!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"]},{"cell_type":"code","source":["# read it in to inspect it\n","with open('input.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()"],"metadata":{"id":"7Hzpl5w1NGp6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"length of dataset in characters: \", len(text))"],"metadata":{"id":"bDLpFUxCNKoI","executionInfo":{"status":"ok","timestamp":1759858645710,"user_tz":240,"elapsed":23,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"f5fd7977-112e-4319-bdf7-3a08c6f54b57","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["length of dataset in characters:  1115394\n"]}]},{"cell_type":"code","source":["# let's look at the first 1000 characters\n","print(text[:1000])"],"metadata":{"id":"UjO47q82NOYX","executionInfo":{"status":"ok","timestamp":1759858645757,"user_tz":240,"elapsed":46,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"f719687b-197d-4653-a8f6-2bf4ae11aa36","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor citizens, the patricians good.\n","What authority surfeits on would relieve us: if they\n","would yield us but the superfluity, while it were\n","wholesome, we might guess they relieved us humanely;\n","but they think we are too dear: the leanness that\n","afflicts us, the object of our misery, is as an\n","inventory to particularise their abundance; our\n","sufferance is a gain to them Let us revenge this with\n","our pikes, ere we become rakes: for the gods know I\n","speak this in hunger for bread, not in thirst for revenge.\n","\n","\n"]}]},{"cell_type":"code","source":["# here are all the unique characters that occur in this text\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lJ5rHF0RKCr","executionInfo":{"status":"ok","timestamp":1759858645800,"user_tz":240,"elapsed":6,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"bdf1cee0-2060-4918-d5a0-ba8ffe7c7943"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}]},{"cell_type":"code","source":["# create a mapping from characters to integers\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n","decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n","\n","print(encode(\"hii there\"))\n","print(decode(encode(\"hii there\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUOuVB-CRPzx","executionInfo":{"status":"ok","timestamp":1759858645800,"user_tz":240,"elapsed":3,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"49f67be0-eda8-41e2-daf4-7b8478d48d88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[46, 47, 47, 1, 58, 46, 43, 56, 43]\n","hii there\n"]}]},{"cell_type":"code","source":["# let's now encode the entire text dataset and store it into a torch.Tensor\n","import torch # we use PyTorch: https://pytorch.org\n","data = torch.tensor(encode(text), dtype=torch.long)\n","print(data.shape, data.dtype)\n","print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJSSq6SdRa4c","executionInfo":{"status":"ok","timestamp":1759858652709,"user_tz":240,"elapsed":6910,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"cf8b5df3-dcee-4598-a960-e2c9d5516de3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1115394]) torch.int64\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n","         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n","        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n","        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n","         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n","         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n","        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n","        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n","         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n","        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n","        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n","        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n","        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n","        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n","        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n","         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n","         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n","         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n","        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n","        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n","        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n","        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n","        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n","        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n","         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n","         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n","        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n","        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n","        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n","         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n","        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n","        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n","         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n","        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n","        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n","        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n","        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n","        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n","        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n","        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n","        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n","        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n","         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n","        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n","        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n","        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n","        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n","        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n","        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"]}]},{"cell_type":"code","source":["# Let's now split up the data into train and validation sets\n","n = int(0.9*len(data)) # first 90% will be train, rest val\n","train_data = data[:n]\n","val_data = data[n:]"],"metadata":{"id":"xfR5WXpxRct-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["block_size = 8\n","train_data[:block_size+1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Poos04IeRfYG","executionInfo":{"status":"ok","timestamp":1759858652714,"user_tz":240,"elapsed":3,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"5cb57cce-eaa8-463c-9ac8-6de6d3df7875"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Y8Km0NxvRAQG"}},{"cell_type":"code","source":["x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","    context = x[:t+1]\n","    target = y[t]\n","    print(f\"when input is {context} the target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PG3PMMqpRCOr","executionInfo":{"status":"ok","timestamp":1759858652717,"user_tz":240,"elapsed":2,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"f390d7a3-8633-4da9-fe47-b4efd49e09a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["when input is tensor([18]) the target: 47\n","when input is tensor([18, 47]) the target: 56\n","when input is tensor([18, 47, 56]) the target: 57\n","when input is tensor([18, 47, 56, 57]) the target: 58\n","when input is tensor([18, 47, 56, 57, 58]) the target: 1\n","when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n","when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"]}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size = 4 # how many independent sequences will we process in parallel?\n","block_size = 8 # what is the maximum context length for predictions?\n","\n","def get_batch(split):\n","  data = train_data if split == 'train' else val_data\n","  ix = torch.randint(len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[i:i+block_size] for i in ix])\n","  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","  return x, y\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape) # 4 x 8\n","print(xb)\n","print('targets:')\n","print(yb.shape) #4 x 8\n","print(yb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYkavUstRq_f","executionInfo":{"status":"ok","timestamp":1759858652720,"user_tz":240,"elapsed":3,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"588151cc-a7f5-4b41-f5df-95177bfd447a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([4, 8])\n","tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n","        [44, 53, 56,  1, 58, 46, 39, 58],\n","        [52, 58,  1, 58, 46, 39, 58,  1],\n","        [25, 17, 27, 10,  0, 21,  1, 54]])\n","targets:\n","torch.Size([4, 8])\n","tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n","        [53, 56,  1, 58, 46, 39, 58,  1],\n","        [58,  1, 58, 46, 39, 58,  1, 46],\n","        [17, 27, 10,  0, 21,  1, 54, 39]])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","torch.manual_seed(1337)\n","\n","class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        logits = self.token_embedding_table(idx) # (B,T,C)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits_new = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits_new, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # get the predictions\n","            logits, loss = self(idx) #B x T x C\n","            logits = logits[:, -1, :] # B x\n","            probs = F.softmax(logits, dim=-1) # B,\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx\n","\n","m = BigramLanguageModel(vocab_size)\n","logits, loss = m(xb, yb)\n","print(logits.shape)\n","print(loss)\n","\n","print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SGNG_nWTKpB","executionInfo":{"status":"ok","timestamp":1759858652810,"user_tz":240,"elapsed":89,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"de8f0644-f19b-4f3b-8ced-bac289e92286"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 8, 65])\n","tensor(4.8786, grad_fn=<NllLossBackward0>)\n","\n","SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n","wnYWmnxKWWev-tDqXErVKLgJ\n"]}]},{"cell_type":"code","source":["# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"],"metadata":{"id":"-LKUsNAxZWuR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","for steps in range(10000): # increase number of steps for good results...\n","\n","    # sample a batch of data\n","    xb, yb = get_batch('train')\n","\n","    # evaluate the loss\n","    logits, loss = m(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n","print(loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ttntzoxZhio","executionInfo":{"status":"ok","timestamp":1759858678308,"user_tz":240,"elapsed":19640,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"d48372aa-914b-46c9-f7c9-a67f95aff795"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.382369041442871\n"]}]},{"cell_type":"code","source":["print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jz_MD_FAaBpX","executionInfo":{"status":"ok","timestamp":1759858678311,"user_tz":240,"elapsed":2,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"c4eed5c9-77c8-4963-f64e-58a03e675730"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","lso br. ave aviasurf my, yxMPZI ivee iuedrd whar ksth y h bora s be hese, woweee; the! KI 'de, ulseecherd d o blllando;LUCEO, oraingofof win!\n","RIfans picspeserer hee tha,\n","TOFonk? me ain ckntoty ded. bo'llll st ta d:\n","ELIS me hurf lal y, ma dus pe athouo\n","BEY:! Indy; by s afreanoo adicererupa anse tecorro llaus a!\n","OLeneerithesinthengove fal amas trr\n","TI ar I t, mes, n IUSt my w, fredeeyove\n","THek' merer, dd\n","We ntem lud engitheso; cer ize helorowaginte the?\n","Thak orblyoruldvicee chot, p,\n","Bealivolde Th li\n"]}]},{"cell_type":"code","source":["# consider the following toy example:\n","\n","torch.manual_seed(1337)\n","B,T,C = 4,8,2 # batch, time, channels\n","x = torch.randn(B,T,C)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nH6henINVez_","executionInfo":{"status":"ok","timestamp":1759868667600,"user_tz":240,"elapsed":45,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"3ae174f6-70de-42be-9479-ac4d7961b461"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 2])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# version 2: using matrix multiply for a weighted aggregation\n","wei = torch.tril(torch.ones(T, T))"],"metadata":{"id":"ppGqjM_MWMFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wei = wei / wei.sum(1, keepdim=True)\n","print(wei)\n","xbow2 = wei @ x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrwFtadmWPZT","executionInfo":{"status":"ok","timestamp":1759868742611,"user_tz":240,"elapsed":45,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"447be644-5d38-4645-f71d-eb8a586d4074"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"]}]},{"cell_type":"code","source":["xbow2[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZk1hR3PWiKz","executionInfo":{"status":"ok","timestamp":1759868758385,"user_tz":240,"elapsed":10,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"bfd4e6d9-3f73-4b43-a220-7fed67b3d78d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1808, -0.0700],\n","        [-0.0894, -0.4926],\n","        [ 0.1490, -0.3199],\n","        [ 0.3504, -0.2238],\n","        [ 0.3525,  0.0545],\n","        [ 0.0688, -0.0396],\n","        [ 0.0927, -0.0682],\n","        [-0.0341,  0.1332]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["x[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omHqSqBhWj-K","executionInfo":{"status":"ok","timestamp":1759868767934,"user_tz":240,"elapsed":12,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"367e1473-d524-40c0-ecdb-d8a8317a7eee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1808, -0.0700],\n","        [-0.3596, -0.9152],\n","        [ 0.6258,  0.0255],\n","        [ 0.9545,  0.0643],\n","        [ 0.3612,  1.1679],\n","        [-1.3499, -0.5102],\n","        [ 0.2360, -0.2398],\n","        [-0.9211,  1.5433]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["tril = torch.tril(torch.ones(T, T))\n","wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","print(wei)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZS4NHLx1XNt7","executionInfo":{"status":"ok","timestamp":1759869027788,"user_tz":240,"elapsed":9,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"648be6ba-76c1-43b5-fcf9-75c43dfa4f3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"]}]},{"cell_type":"code","source":["# version 4: self-attention!\n","torch.manual_seed(1337)\n","B,T,C = 4,8,32 # batch, time, channels\n","x = torch.randn(B,T,C)\n","\n","# let's see a single Head perform self-attention\n","head_size = 16\n","key = nn.Linear(C, head_size, bias=False)\n","query = nn.Linear(C, head_size, bias=False)\n","value = nn.Linear(C, head_size, bias=False)\n","\n","k = key(x) #(B, T, head_size)\n","q = query(x) #(B, T, head_size)\n","wei = q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) ---> (B, T, T)\n","\n","tril = torch.tril(torch.ones(T, T))\n","#wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","\n","v = value(x)\n","out = wei @ v #(B, T, 16)"],"metadata":{"id":"CwwjR5gEX2oj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k = torch.randn(B,T,head_size)\n","q = torch.randn(B,T,head_size)\n","\n","\n","# comment and uncomment\n","wei = q @ k.transpose(-2, -1) * head_size**(-0.5)"],"metadata":{"id":"IWDhXe7hZ22U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wei.var()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yL4sn378aLCn","executionInfo":{"status":"ok","timestamp":1759869867802,"user_tz":240,"elapsed":9,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"4d52130a-45ff-4527-a8cd-af0b5082fca5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9957)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1) #very close to 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyWlziCvaPwD","executionInfo":{"status":"ok","timestamp":1759869781483,"user_tz":240,"elapsed":4,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"e9d42062-5152-4826-9b9b-10de14a7f21f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUZ3ZknbaXH1","executionInfo":{"status":"ok","timestamp":1759869787497,"user_tz":240,"elapsed":7,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"24b426ef-46e5-47fc-ba73-ca02896a0aa1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["print(wei)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c23rWN20ZN7F","executionInfo":{"status":"ok","timestamp":1759869466761,"user_tz":240,"elapsed":46,"user":{"displayName":"Courtney Paquette","userId":"13393751932587136950"}},"outputId":"38c9e0a3-e7e6-4f53-c3c9-3d2d1400cf07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n","         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n","         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n","         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n","         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n","         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n","         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n","         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n","         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n","         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n","         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n","         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n","         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n","       grad_fn=<SoftmaxBackward0>)\n"]}]}]}